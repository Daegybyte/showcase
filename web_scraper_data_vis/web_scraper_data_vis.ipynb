{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diego u0283930\n",
    "### Homework 3\n",
    "[Robots file](https://news.ycombinator.com/robots.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request\n",
    "import time\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first num_pages\n",
    "def get_html_pages(num_pages):\n",
    "    html = \"\"\n",
    "    for i in range (num_pages):\n",
    "        url = \"https://news.ycombinator.com/news?p=\" + str(i+1)\n",
    "        tmp = \"\"\n",
    "        with urllib.request.urlopen( url ) as response:\n",
    "            tmp = response.read()\n",
    "            html = html + tmp.decode( 'utf-8' )\n",
    "            print(f\"scraping {url}\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "    # save the file\n",
    "    name = \"hacker_news.html\"\n",
    "    with open( name, 'w' ) as new_file:\n",
    "        new_file.write(html)\n",
    "\n",
    "get_html_pages(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the soup from local file\n",
    "file = \"hacker_news.html\"\n",
    "with open (file, 'r') as f:\n",
    "    html = str(f.readlines())\n",
    "\n",
    "soup = bs( html, 'html.parser' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = soup.select(\".rank\")\n",
    "ranks = [int(tag.string[:-1]) for tag in ranks] # for academic practice. Could just use a loop 1 - 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soup.select(\".titlelink\")\n",
    "titles_length = [ len(tag.get_text()) for tag in titles ]\n",
    "assert(len(titles_length) == len(ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_converted_time(age):\n",
    "    time = age[0]\n",
    "    unit = age[1]\n",
    "    if \"minute\" in unit:\n",
    "        return time / 60\n",
    "    elif \"hour\" in unit:\n",
    "        return time\n",
    "    elif \"day\" in unit:\n",
    "        return time * 24\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_since_post = []\n",
    "ages = soup.find_all( \"span\", class_=\"age\" )\n",
    "for el in ages:\n",
    "    age = el.get_text()\n",
    "    age = age.split()\n",
    "    ints = [str(integer) for integer in age[0]]\n",
    "    age[0]  = \"\".join(ints)\n",
    "    age[0]  = float(age[0]) \n",
    "    age[0] = get_converted_time(age)\n",
    "    time_since_post.append(age[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = soup.select(\".subtext\")\n",
    "points = []\n",
    "for tag in sub:\n",
    "    tmp = tag.get_text().split()[2:4]\n",
    "    # print(tmp)\n",
    "    if tmp[1] == \"points\":\n",
    "        points.append(int(tmp[0]))\n",
    "    else:\n",
    "        points.append(1)\n",
    "\n",
    "assert(len(titles_length) == len(ranks) and len(titles_length) == len(time_since_post) and len(time_since_post) == len(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "for tag in sub:\n",
    "    tmp = tag.get_text().split()\n",
    "    # print(tmp)\n",
    "    if tmp[-1] == \"comments\" or tmp[-1] == \"comment\":\n",
    "        comments.append(int(tmp[-2]))\n",
    "    else:\n",
    "        comments.append(0)\n",
    "\n",
    "assert(len(titles_length) == len(ranks) and len(titles_length) == len(time_since_post) and len(time_since_post) == len(points) and len(points) == len(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"rank\":ranks,\n",
    "        \"len_titles\":titles_length,  \n",
    "        \"time_since_post\":time_since_post, \n",
    "        \"points\":points, \n",
    "        \"comments\":comments\n",
    "        }\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False )\n",
    "df_CSV = pd.read_csv(\"data.csv\")\n",
    "df_CSV.reindex(columns=data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = df_CSV[[\"rank\", \"time_since_post\", \"points\"]]\n",
    "data_ols = sm.ols(formula=\"rank ~ time_since_post + points\", data=plot_data ).fit()\n",
    "\n",
    "hours_and_points = data_ols.params[\"Intercept\"] + (data_ols.params[\"points\"] * df[\"points\"]) + (data_ols.params[\"time_since_post\"] * df[\"time_since_post\"])\n",
    "hours_and_points\n",
    "df[\"hours_and_points\"] = hours_and_points\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.scatter(x=df[[\"hours_and_points\"]], y=df[\"rank\"], color=\"purple\")\n",
    "    plt.plot(df[\"hours_and_points\"],data_ols.predict(), label=\"best fit\", linewidth=1, color=\"lightblue\")\n",
    "    plt.xlabel(\"hours since post and points\")\n",
    "    plt.ylabel(\"Rank\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ols.summary()\n",
    "# R-squared:\t                0.394\n",
    "# coef:         time_since_post\t3.2406\n",
    "#               points\t        -0.0912\t\n",
    "\n",
    "# p-val         time_since_post 0.000\t\n",
    "#               points          0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the ols of all columns\n",
    "df_CSV = pd.read_csv(\"data.csv\")\n",
    "df_CSV.reindex(columns=data.keys())\n",
    "data_ols = sm.ols(formula=\"rank ~ len_titles + points + time_since_post + comments\", data=data ).fit()\n",
    "data_ols.summary()\n",
    "# R-squared:\t                0.397\n",
    "# coef:         len_titles\t    0.1011\n",
    "#               points\t        -0.0963\n",
    "#               time_since_post 3.2550\n",
    "#               comments        0.0154\n",
    "\n",
    "# p-val:        len_titles\t    0.496\n",
    "#               points\t        0.000\t\t\n",
    "#               time_since_post 0.000\n",
    "#               comments        0.593"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the rank to the time since post\n",
    "data_ols = sm.ols(formula=\"rank ~ time_since_post\", data=data ).fit()\n",
    "data_ols.summary()\n",
    "# R-squared:\t                0.277\n",
    "# coef:       \ttime_since_post 2.1901\n",
    "\n",
    "# p-val:      \ttime_since_post 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.corr()\n",
    "labels = df.keys()\n",
    "with plt.xkcd():\n",
    "    grid = plt.imshow(matrix, cmap=\"tab20c\", vmax= 1, vmin= -1)\n",
    "    plt.colorbar(grid, shrink=.8)\n",
    "    plt.xticks(np.arange(len(labels)), labels=labels, rotation = 90)\n",
    "    plt.yticks(np.arange(len(labels)), labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = df[['rank', 'points', 'len_titles', 'time_since_post', \"comments\"]]\n",
    "with plt.xkcd():\n",
    "    pd.plotting.scatter_matrix(plot_data, figsize=(10, 10), diagonal='kde', color=\"grey\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write up\n",
    "It appears there is a linear relationsip between age and rank. points and comments, a relationship between points and time. Age appears to be the biggest contributing factor to where a post ranks. Rank compared to lenghth of titles is a terrible comparison, the data is all over the place.\n",
    "\n",
    "\n",
    "The r squared vals are low, so it appears that none of this stuff is really correlated. The best is age. But, they are all bad variables.\n",
    "This data will change depending on source file and time scraped\n",
    "\n",
    "\n",
    "What our regressions tell us about being on the front page is that it helps to have a high score and to have not been there for very long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_on_front_page\"] = [int(row <= 30) for row in df[\"rank\"]] # add a 1 to rows on front page, 0 otherwise\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = ((df[\"points\"] -1) ** .8 / (df[\"time_since_post\"] + 2) ** 1.8)\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) #display full dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax = fig.add_axes([1,1,1,1])\n",
    "    ax.set_title(\"Front page predicted\\nStories above line predicted to be on front page\")\n",
    "    ax.set_xlabel(\"rank\")\n",
    "    ax.set_ylabel(\"calculated score\")\n",
    "    df_front = df[df[\"is_on_front_page\"] == 1] #create new data frames with 1 and 0\n",
    "    df_not_front = df[df[\"is_on_front_page\"] == 0]\n",
    "    ax.scatter(x=df_front[\"rank\"], y=df_front[\"score\"], label=\"on front page\")\n",
    "    ax.scatter(x=df_not_front[\"rank\"], y=df_not_front[\"score\"], label=\"not on front page\", c=\"grey\")\n",
    "    sorted = df[\"score\"].sort_values(ascending=False)\n",
    "    cutoff = sorted.iloc[29]\n",
    "    ax.axhline(y=cutoff, color=\"purple\") #cutoff score\n",
    "    ax.legend()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax = fig.add_axes([1,1,1,1])\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Front Page\")\n",
    "\n",
    "    logit_res = sm.logit(formula=\"is_on_front_page ~ score\", data=df).fit()\n",
    "    results = logit_res.predict()\n",
    "\n",
    "    logistic_sigmoid_func = lambda x: 1 / ( 1 + np.exp(-x) )\n",
    "    ax.scatter(x=df[\"score\"], y=df[\"is_on_front_page\"])   \n",
    "    logit_param = dict(logit_res.params)\n",
    "\n",
    "    xs = np.linspace( df[\"score\"].min(), df[\"score\"].max(), 1000 )\n",
    "    ys = logistic_sigmoid_func( logit_param[\"Intercept\"] + logit_param[\"score\"] * xs )\n",
    "\n",
    "    fifty_percent = np.interp(0.5, ys, xs)\n",
    "\n",
    "    ax.plot( xs, ys, color=\"Black\") # Smushed line\n",
    "    ax.plot([ fifty_percent, fifty_percent], [0,1], \"r\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
